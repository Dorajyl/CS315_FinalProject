{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9240af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96323db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/edithpo/Documents/CS315/CS315_FinalProject'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3154bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompleteDateTime.ipynb           \u001b[34mmerged datasets\u001b[m\u001b[m/\r\n",
      "README.md                        \u001b[34mpyktok_data\u001b[m\u001b[m/\r\n",
      "cs315project2datacollection.zip  topic_modeling.ipynb\r\n",
      "exploratory_analysis.ipynb       \u001b[34muser_jsons\u001b[m\u001b[m/\r\n",
      "looking_at_jsons.ipynb           \u001b[34muser_jsons_tosplit\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde17e4a",
   "metadata": {},
   "source": [
    "## Explore Data from our JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "64569355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sec1Gr3_11111.json',\n",
       " '.DS_Store',\n",
       " 'Sec1Gr1_10824.json',\n",
       " 'Sec2Gr2_69117.json',\n",
       " 'Sec1Gr1_50405.json',\n",
       " 'Sec2Gr2_33534.json',\n",
       " 'Sec1Gr1_12345.json',\n",
       " 'Sec2Gr2_26301.json',\n",
       " 'Sec2Gr2_38129.json']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('user_jsons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ac141ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = ['10824','11111','12345','26301','33534','38129','50405']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ecaaa971",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = ['Sec1Gr1_10824.json',\n",
    "              'Sec1Gr3_11111.json',\n",
    "              'Sec1Gr1_12345.json',\n",
    "              'Sec2Gr2_26301.json',\n",
    "              'Sec2Gr2_33534.json',\n",
    "              'Sec2Gr2_38129.json',\n",
    "              'Sec1Gr1_50405.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "03b49fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_jsons(filename):\n",
    "    # Load data\n",
    "    with open(f'user_jsons/{filename}') as fin:\n",
    "        data = json.load(fin)\n",
    "        \n",
    "        # Process data in dictionary format\n",
    "        if type(data) == dict:\n",
    "            print(f\"{filename} data loaded as a dictionary.\")\n",
    "            print(f\"Original Keys: {data.keys()}\")\n",
    "            print(f\"Retrieving data list from the 'data' key.\")\n",
    "            data_list_of_lists = data['data'] # retrieve only the timestamp and link as list\n",
    "            print(f\"First element of data list:\")\n",
    "            print(data_list_of_lists[0])\n",
    "            print(\"Transforming into list of dicts format:\")\n",
    "            data_list_of_dicts = [{'Date':elt[0],'Link':elt[1]} for elt in data_list_of_lists]\n",
    "            print(data_list_of_dicts[0])\n",
    "        else:\n",
    "            data_list_of_dicts = data\n",
    "            print(f\"{filename} data loaded as a list of dictionaries.\")\n",
    "            print(f\"First element of data list:\")\n",
    "            print(data_list_of_dicts[0])\n",
    "            \n",
    "    return data_list_of_dicts\n",
    "\n",
    "def get_video_id(link):\n",
    "    # Define the regex pattern\n",
    "    pattern = r'\\/(\\d+)\\/$'\n",
    "    match = re.search(pattern, link)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        print(f\"No match for link {link}\")\n",
    "        return \"\"\n",
    "    \n",
    "    \n",
    "def make_jsondf(filename):\n",
    "    '''Given filename of data file in user_json folder, \n",
    "    loads and saves data to new df with columns for watch time and link.\n",
    "    Adds a column for the user and for the video id.'''\n",
    "    # Get list of timestamps and links from json file\n",
    "    data = process_jsons(filename)\n",
    "    \n",
    "    # Create dataframe from the timestamp and link\n",
    "    json_df = pd.DataFrame(data,columns=['Date','Link'])\n",
    "    \n",
    "    # Add code column\n",
    "    json_df['Date'] = pd.to_datetime(json_df['Date'])\n",
    "    json_df['Month'] = json_df['Date'].apply(lambda date: date.month)\n",
    "    json_df['Year'] = json_df['Date'].apply(lambda date: date.year)\n",
    "    json_df['code'] = filename[-10:-5]\n",
    "    json_df['video_id'] = json_df['Link'].apply(get_video_id)\n",
    "    return json_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "68292681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sec1Gr1_10824.json data loaded as a dictionary.\n",
      "Original Keys: dict_keys(['columns', 'index', 'data'])\n",
      "Retrieving data list from the 'data' key.\n",
      "First element of data list:\n",
      "['2024-02-09 23:35:22', 'https://www.tiktokv.com/share/video/7328672125441658117/']\n",
      "Transforming into list of dicts format:\n",
      "{'Date': '2024-02-09 23:35:22', 'Link': 'https://www.tiktokv.com/share/video/7328672125441658117/'}\n",
      "Sec1Gr3_11111.json data loaded as a list of dictionaries.\n",
      "First element of data list:\n",
      "{'Date': '2024-03-02 21:51:57', 'Link': 'https://www.tiktokv.com/share/video/7341119211109961003/'}\n",
      "Sec1Gr1_12345.json data loaded as a dictionary.\n",
      "Original Keys: dict_keys(['columns', 'index', 'data'])\n",
      "Retrieving data list from the 'data' key.\n",
      "First element of data list:\n",
      "['2024-02-26 02:58:45', 'https://www.tiktokv.com/share/video/7331569476502064414/']\n",
      "Transforming into list of dicts format:\n",
      "{'Date': '2024-02-26 02:58:45', 'Link': 'https://www.tiktokv.com/share/video/7331569476502064414/'}\n",
      "Sec2Gr2_26301.json data loaded as a list of dictionaries.\n",
      "First element of data list:\n",
      "{'Date': '2024-03-06 19:44:41', 'Link': 'https://www.tiktokv.com/share/video/7315561816673750318/'}\n",
      "Sec2Gr2_33534.json data loaded as a list of dictionaries.\n",
      "First element of data list:\n",
      "{'Date': '2024-02-03 22:32:47', 'Link': 'https://www.tiktokv.com/share/video/7331462048699649323/'}\n",
      "Sec2Gr2_38129.json data loaded as a list of dictionaries.\n",
      "First element of data list:\n",
      "{'Date': '2024-03-08 03:42:17', 'Link': 'https://www.tiktokv.com/share/video/7343758155492642053/'}\n",
      "Sec1Gr1_50405.json data loaded as a dictionary.\n",
      "Original Keys: dict_keys(['columns', 'index', 'data'])\n",
      "Retrieving data list from the 'data' key.\n",
      "First element of data list:\n",
      "['2023-11-18 01:27:59', 'https://www.tiktokv.com/share/video/7298064289510804779/']\n",
      "Transforming into list of dicts format:\n",
      "{'Date': '2023-11-18 01:27:59', 'Link': 'https://www.tiktokv.com/share/video/7298064289510804779/'}\n"
     ]
    }
   ],
   "source": [
    "df10824 = make_jsondf('Sec1Gr1_10824.json')\n",
    "df11111 = make_jsondf('Sec1Gr3_11111.json')\n",
    "df12345 = make_jsondf('Sec1Gr1_12345.json')\n",
    "df26301 = make_jsondf('Sec2Gr2_26301.json')\n",
    "df33534 = make_jsondf('Sec2Gr2_33534.json')\n",
    "df38129 = make_jsondf('Sec2Gr2_38129.json')\n",
    "df50405 = make_jsondf('Sec1Gr1_50405.json')\n",
    "df_list = [df10824,df11111,df12345,df33534,df38129,df50405]\n",
    "all_json = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "45df7358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>code</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-09 23:35:22</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7328672125...</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>10824</td>\n",
       "      <td>7328672125441658117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-26 23:29:56</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7326611895...</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>10824</td>\n",
       "      <td>7326611895509585185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-26 23:28:15</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7324765984...</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>10824</td>\n",
       "      <td>7324765984139644192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-26 23:27:53</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7329768535...</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>10824</td>\n",
       "      <td>7329768535524429102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-26 23:27:42</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7338541911...</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>10824</td>\n",
       "      <td>7338541911629745414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26112</th>\n",
       "      <td>2023-08-05 01:01:28</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7259854730...</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>50405</td>\n",
       "      <td>7259854730082536747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26113</th>\n",
       "      <td>2023-08-05 01:01:06</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7262065549...</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>50405</td>\n",
       "      <td>7262065549394365702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26114</th>\n",
       "      <td>2023-08-05 01:01:03</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7250606200...</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>50405</td>\n",
       "      <td>7250606200684055854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26115</th>\n",
       "      <td>2023-08-05 00:37:57</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7263265961...</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>50405</td>\n",
       "      <td>7263265961359281413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26116</th>\n",
       "      <td>2023-08-05 00:20:07</td>\n",
       "      <td>https://www.tiktokv.com/share/video/7262829334...</td>\n",
       "      <td>8</td>\n",
       "      <td>2023</td>\n",
       "      <td>50405</td>\n",
       "      <td>7262829334925200686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141227 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date                                               Link  \\\n",
       "0     2024-02-09 23:35:22  https://www.tiktokv.com/share/video/7328672125...   \n",
       "1     2024-02-26 23:29:56  https://www.tiktokv.com/share/video/7326611895...   \n",
       "2     2024-02-26 23:28:15  https://www.tiktokv.com/share/video/7324765984...   \n",
       "3     2024-02-26 23:27:53  https://www.tiktokv.com/share/video/7329768535...   \n",
       "4     2024-02-26 23:27:42  https://www.tiktokv.com/share/video/7338541911...   \n",
       "...                   ...                                                ...   \n",
       "26112 2023-08-05 01:01:28  https://www.tiktokv.com/share/video/7259854730...   \n",
       "26113 2023-08-05 01:01:06  https://www.tiktokv.com/share/video/7262065549...   \n",
       "26114 2023-08-05 01:01:03  https://www.tiktokv.com/share/video/7250606200...   \n",
       "26115 2023-08-05 00:37:57  https://www.tiktokv.com/share/video/7263265961...   \n",
       "26116 2023-08-05 00:20:07  https://www.tiktokv.com/share/video/7262829334...   \n",
       "\n",
       "       Month  Year   code             video_id  \n",
       "0          2  2024  10824  7328672125441658117  \n",
       "1          2  2024  10824  7326611895509585185  \n",
       "2          2  2024  10824  7324765984139644192  \n",
       "3          2  2024  10824  7329768535524429102  \n",
       "4          2  2024  10824  7338541911629745414  \n",
       "...      ...   ...    ...                  ...  \n",
       "26112      8  2023  50405  7259854730082536747  \n",
       "26113      8  2023  50405  7262065549394365702  \n",
       "26114      8  2023  50405  7250606200684055854  \n",
       "26115      8  2023  50405  7263265961359281413  \n",
       "26116      8  2023  50405  7262829334925200686  \n",
       "\n",
       "[141227 rows x 6 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "013fdd79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code   Year  Month\n",
       "10824  2023  11       14114\n",
       "             12        2940\n",
       "       2024  2         9213\n",
       "11111  2023  9         3547\n",
       "             10        5743\n",
       "             11        4325\n",
       "             12        4960\n",
       "       2024  1         6101\n",
       "             2         2699\n",
       "             3          561\n",
       "12345  2023  9         2985\n",
       "             11        1964\n",
       "             12        5558\n",
       "       2024  1         5299\n",
       "             2         4038\n",
       "             3          777\n",
       "33534  2023  9         5075\n",
       "             10        5652\n",
       "             11        7317\n",
       "             12        8746\n",
       "       2024  1         9758\n",
       "             2         3706\n",
       "38129  2024  2           25\n",
       "             3            7\n",
       "50405  2023  8        10053\n",
       "             9         1044\n",
       "             10        1540\n",
       "             11        1003\n",
       "             12        6047\n",
       "       2024  1         6295\n",
       "             2          135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of videos in each year/month for each user\n",
    "all_json.groupby('code')[['Year','Month']].value_counts().sort_index()\n",
    "\n",
    "\n",
    "# # Code to do the same thing\n",
    "# for df, code in zip(df_list,codes):\n",
    "#     print(\"User\",code)\n",
    "#     print(df[['Year','Month']].value_counts().sort_index())\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3c788",
   "metadata": {},
   "source": [
    "## Reformat JSON Files for Data Collection - USER 26301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1c8df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.listdir('user_jsons_tosplit'))\n",
    "\n",
    "# def convert2json(row):\n",
    "#     result = {\"Date\":row[\"Date\"],\n",
    "#               \"Link\":row[\"Link\"]}\n",
    "#     return result\n",
    "\n",
    "# # Add a new column with correctly formatted dict\n",
    "# user26301 = make_json_df('Sec2Gr2_26301.json',26301)\n",
    "# user26301[\"dict\"] = user26301.apply(convert2json, axis=1)\n",
    "# print(user26301.shape)\n",
    "# print(user26301.head())\n",
    "\n",
    "\n",
    "# # Turn into list\n",
    "# user26301 = user26301['dict'].tolist()\n",
    "\n",
    "# print(len(user26301))\n",
    "\n",
    "# # Split the df into parts\n",
    "# part1 = user26301[:12000]\n",
    "# part2 = user26301[12000:24000]\n",
    "# part3 = user26301[24000:36000]\n",
    "# part4 = user26301[36000:48000]\n",
    "# part5 = user26301[48000:60000]\n",
    "# part6 = user26301[72000:82371]\n",
    "\n",
    "\n",
    "# parts = [part1, part2, part3, part4, part5, part6]\n",
    "# fnames = ['Sec2Gr2_26301_1.json','Sec2Gr2_26301_2.json',\n",
    "#           'Sec2Gr2_26301_3.json','Sec2Gr2_26301_4.json',\n",
    "#           'Sec2Gr2_26301_5.json','Sec2Gr2_26301_6.json']\n",
    "    \n",
    "# for part, fn in zip(parts, fnames):\n",
    "#     with open(f\"user_jsons_tosplit/{fn}\",\"w\") as outfile:\n",
    "#         json_object = json.dumps(part, indent=4)\n",
    "#         outfile.write(json_object)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393c575",
   "metadata": {},
   "source": [
    "## Check JSON Data Against Pyktok Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fdab0c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results_12345.csv',\n",
       " 'results_50405.csv',\n",
       " 'results_50405_full.csv',\n",
       " 'results_12345(19019 rows).csv',\n",
       " 'results_10824.2.csv',\n",
       " 'results_50405_secondHalf.csv',\n",
       " 'results_10824.csv',\n",
       " 'results_10824_full.csv']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('other_pyktok_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c29ffbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyk10824 = pd.read_csv('other_pyktok_data/results_10824_full.csv')\n",
    "pyk12345 = pd.read_csv('other_pyktok_data/results_12345(19019 rows).csv') \n",
    "pyk50405 = pd.read_csv('other_pyktok_data/results_50405_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01c385",
   "metadata": {},
   "source": [
    "### Load Pyktok Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2d97fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"d10824 = pd.read_csv('pyktok_data/Sec1Gr1_10824.csv')\n",
    "df10824 = df10824.loc[:,keep_cols]\n",
    "\n",
    "df11111_original = pd.read_csv('pyktok_data/Sec1Gr3_11111.csv')\n",
    "df11111_original = df11111_original.loc[:,keep_cols]\n",
    "\n",
    "df12345 = pd.read_csv('pyktok_data/Sec1Gr1_12345.csv')\n",
    "df12345 = df12345.loc[:,keep_cols]\n",
    "\n",
    "df26301 = pd.read_csv('pyktok_data/Sec1Gr2_26301.csv')\n",
    "df26301 = df26301.loc[:,keep_cols]\n",
    "\n",
    "df33534 = pd.read_csv('pyktok_data/Sec1Gr2_33534.csv')\n",
    "df33534 = df33534.loc[:,keep_cols]\n",
    "\n",
    "df38129 = pd.read_csv('pyktok_data/Sec1Gr2_38129.csv')\n",
    "df38129 = df38129.loc[:,keep_cols]\n",
    "\n",
    "df50405 = pd.read_csv('pyktok_data/Sec1Gr1_50405.csv')\n",
    "df50405 = df50405.loc[:,keep_cols]\"\"\".replace('df','pyk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18aada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2d2b0ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pyktok_data/Sec1Gr1_10824.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m keep_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_is_ad\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_username\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuggested_words\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ['video_id', 'video_timestamp', 'video_duration',\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#        'video_locationcreated', 'suggested_words', 'video_diggcount',\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#        'video_sharecount', 'video_commentcount', 'video_playcount',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#        'author_heartcount', 'author_videocount', 'author_diggcount',\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#        'author_verified']\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df10824 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyktok_data/Sec1Gr1_10824.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m df10824 \u001b[38;5;241m=\u001b[39m df10824\u001b[38;5;241m.\u001b[39mloc[:,keep_cols]\n\u001b[1;32m     15\u001b[0m df11111_original \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyktok_data/Sec1Gr3_11111.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[1;32m    869\u001b[0m     _doc_read_csv_and_table\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    870\u001b[0m         func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[1;32m    942\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m TextFileReader:\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keep_date_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m    944\u001b[0m         \u001b[38;5;66;03m# GH#55569\u001b[39;00m\n\u001b[1;32m    945\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    946\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep_date_col\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword in pd.read_csv is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    947\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. Explicitly remove unwanted \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 948\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns after parsing instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    949\u001b[0m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    950\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    951\u001b[0m         )\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m         keep_date_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    607\u001b[0m     if chunksize is not None:\n\u001b[1;32m    608\u001b[0m         raise ValueError(\n\u001b[1;32m    609\u001b[0m             \"The 'chunksize' option is not supported with the 'pyarrow' engine\"\n\u001b[1;32m    610\u001b[0m         )\n\u001b[0;32m--> 611\u001b[0m else:\n\u001b[1;32m    612\u001b[0m     chunksize = validate_integer(\"chunksize\", chunksize, 1)\n\u001b[1;32m    614\u001b[0m nrows = kwds.get(\"nrows\", None)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_fwf\u001b[39m(\n\u001b[1;32m   1425\u001b[0m     filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadCsvBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m ReadCsvBuffer[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[1;32m   1434\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TextFileReader:\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_fwf\u001b[39m(\n\u001b[1;32m   1440\u001b[0m     filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadCsvBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m ReadCsvBuffer[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1442\u001b[0m     colspecs: Sequence[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   1443\u001b[0m     widths: Sequence[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   1444\u001b[0m     infer_nrows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   1445\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   1446\u001b[0m     iterator: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   1447\u001b[0m     chunksize: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[0;32m-> 1448\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[1;32m   1449\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_fwf\u001b[39m(\n\u001b[1;32m   1454\u001b[0m     filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadCsvBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m ReadCsvBuffer[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[1;32m   1463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m TextFileReader:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m delim_whitespace:\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1703\u001b[0m         fallback_reason \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1704\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m engine does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msep=None with delim_whitespace=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1706\u001b[0m         )\n\u001b[1;32m   1707\u001b[0m         engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sep) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;66;03m# Unrecognized Compression\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    862\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized compression type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompression\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    866\u001b[0m handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pyktok_data/Sec1Gr1_10824.csv'"
     ]
    }
   ],
   "source": [
    "keep_cols = ['video_id', 'video_is_ad','author_username','author_name',\n",
    "             'suggested_words','video_description']\n",
    "\n",
    "# ['video_id', 'video_timestamp', 'video_duration',\n",
    "#        'video_locationcreated', 'suggested_words', 'video_diggcount',\n",
    "#        'video_sharecount', 'video_commentcount', 'video_playcount',\n",
    "#        'video_description', 'video_is_ad', 'video_stickers', 'author_username',\n",
    "#        'author_name', 'author_followercount', 'author_followingcount',\n",
    "#        'author_heartcount', 'author_videocount', 'author_diggcount',\n",
    "#        'author_verified']\n",
    "\n",
    "d10824 = pd.read_csv('pyktok_data/Sec1Gr1_10824.csv')\n",
    "df10824 = df10824.loc[:,keep_cols]\n",
    "\n",
    "df11111_original = pd.read_csv('pyktok_data/Sec1Gr3_11111.csv')\n",
    "df11111_original = df11111_original.loc[:,keep_cols]\n",
    "\n",
    "df12345 = pd.read_csv('pyktok_data/Sec1Gr1_12345.csv')\n",
    "df12345 = df12345.loc[:,keep_cols]\n",
    "\n",
    "df26301 = pd.read_csv('pyktok_data/Sec1Gr2_26301.csv')\n",
    "df26301 = df26301.loc[:,keep_cols]\n",
    "\n",
    "df33534 = pd.read_csv('pyktok_data/Sec1Gr2_33534.csv')\n",
    "df33534 = df33534.loc[:,keep_cols]\n",
    "\n",
    "df38129 = pd.read_csv('pyktok_data/Sec1Gr2_38129.csv')\n",
    "df38129 = df38129.loc[:,keep_cols]\n",
    "\n",
    "df50405 = pd.read_csv('pyktok_data/Sec1Gr1_50405.csv')\n",
    "df50405 = df50405.loc[:,keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6bd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

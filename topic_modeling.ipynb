{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32807f97",
   "metadata": {},
   "source": [
    "<br>Dora Li\n",
    "<br>CS315 \n",
    "<br>April 23rd, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aaaa99",
   "metadata": {},
   "source": [
    "# Topic Modeling for Advertisements in TikTok Video History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6bd4b-cf18-48eb-978e-b4a1933cc4ef",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639a2fcd-bf16-4e30-bf5a-2c6657f74135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d69651a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>video_locationcreated</th>\n",
       "      <th>suggested_words</th>\n",
       "      <th>video_diggcount</th>\n",
       "      <th>video_sharecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>video_playcount</th>\n",
       "      <th>video_description</th>\n",
       "      <th>video_is_ad</th>\n",
       "      <th>video_stickers</th>\n",
       "      <th>author_username</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_followercount</th>\n",
       "      <th>author_followingcount</th>\n",
       "      <th>author_heartcount</th>\n",
       "      <th>author_videocount</th>\n",
       "      <th>author_diggcount</th>\n",
       "      <th>author_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>7342923622752767278</td>\n",
       "      <td>2024-03-05T12:44:54</td>\n",
       "      <td>15.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Skating Board, tubi movie, tubi movies 2023, t...</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1300000.0</td>\n",
       "      <td>They're bringing new vibes to old traditions. ...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>tubi</td>\n",
       "      <td>Tubi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>7340530115241053486</td>\n",
       "      <td>2024-02-28T01:06:58</td>\n",
       "      <td>59.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Karaoke Machine, Karaoke, Playing Karaoke, car...</td>\n",
       "      <td>14200.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>You cant even tell on video how loud this gets...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>kaitttttnicole</td>\n",
       "      <td>Kait</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7302183353237703967</td>\n",
       "      <td>2023-11-16T17:01:05</td>\n",
       "      <td>35.0</td>\n",
       "      <td>US</td>\n",
       "      <td>heated round brush, wavytalk, wavy talk 5 in 1...</td>\n",
       "      <td>40800.0</td>\n",
       "      <td>3345.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>5400000.0</td>\n",
       "      <td>Replying to @lily  TikTok shop black friday sa...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>julissa_guillen</td>\n",
       "      <td>Julissa Guillen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7313262803266161962</td>\n",
       "      <td>2023-12-16T13:35:03</td>\n",
       "      <td>17.0</td>\n",
       "      <td>US</td>\n",
       "      <td>wavytalk brush, wavy talk, wavy thermal brush,...</td>\n",
       "      <td>157900.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>im not even kidding like this guy is comign w ...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>jigglyjulia</td>\n",
       "      <td>julia huynh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7336608256384585002</td>\n",
       "      <td>2024-02-17T11:27:29</td>\n",
       "      <td>49.0</td>\n",
       "      <td>US</td>\n",
       "      <td>wavy thermal brush, Thermal Brush, wavytalk br...</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>feeling like this viral @wavytalkofficial is w...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>zoeyburger</td>\n",
       "      <td>zoeyburger</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                video_id      video_timestamp  video_duration  \\\n",
       "112  7342923622752767278  2024-03-05T12:44:54            15.0   \n",
       "120  7340530115241053486  2024-02-28T01:06:58            59.0   \n",
       "125  7302183353237703967  2023-11-16T17:01:05            35.0   \n",
       "131  7313262803266161962  2023-12-16T13:35:03            17.0   \n",
       "135  7336608256384585002  2024-02-17T11:27:29            49.0   \n",
       "\n",
       "    video_locationcreated                                    suggested_words  \\\n",
       "112                    US  Skating Board, tubi movie, tubi movies 2023, t...   \n",
       "120                    US  Karaoke Machine, Karaoke, Playing Karaoke, car...   \n",
       "125                    US  heated round brush, wavytalk, wavy talk 5 in 1...   \n",
       "131                    US  wavytalk brush, wavy talk, wavy thermal brush,...   \n",
       "135                    US  wavy thermal brush, Thermal Brush, wavytalk br...   \n",
       "\n",
       "     video_diggcount  video_sharecount  video_commentcount  video_playcount  \\\n",
       "112           1031.0              18.0                12.0        1300000.0   \n",
       "120          14200.0             706.0                65.0         249000.0   \n",
       "125          40800.0            3345.0               355.0        5400000.0   \n",
       "131         157900.0             680.0               315.0        8000000.0   \n",
       "135          10100.0             363.0                66.0        1600000.0   \n",
       "\n",
       "                                     video_description  video_is_ad  \\\n",
       "112  They're bringing new vibes to old traditions. ...         True   \n",
       "120  You cant even tell on video how loud this gets...         True   \n",
       "125  Replying to @lily  TikTok shop black friday sa...         True   \n",
       "131  im not even kidding like this guy is comign w ...         True   \n",
       "135  feeling like this viral @wavytalkofficial is w...         True   \n",
       "\n",
       "    video_stickers  author_username      author_name author_followercount  \\\n",
       "112                            tubi             Tubi                        \n",
       "120                  kaitttttnicole             Kait                        \n",
       "125                 julissa_guillen  Julissa Guillen                        \n",
       "131                     jigglyjulia      julia huynh                        \n",
       "135                      zoeyburger       zoeyburger                        \n",
       "\n",
       "    author_followingcount author_heartcount author_videocount  \\\n",
       "112                                                             \n",
       "120                                                             \n",
       "125                                                             \n",
       "131                                                             \n",
       "135                                                             \n",
       "\n",
       "    author_diggcount  author_verified  \n",
       "112                              True  \n",
       "120                             False  \n",
       "125                             False  \n",
       "131                             False  \n",
       "135                             False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data and get advertisements\n",
    "df = pd.read_csv(\"results_26301.csv\")\n",
    "ads = df[df[\"video_is_ad\"] == True]\n",
    "ads = ads.fillna(\"\") # make sure there is no na values\n",
    "ads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bb5a5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1079, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e687f-0552-4aea-a9ac-9a28de5d978a",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## 2. Convert to document-term matrix\n",
    "\n",
    "We will apply the CountVectorizer to convert our corpus into a document-term matrix. Empirical evidence has shown that simply counting words is more meaningful for performing LDA on documents. (It is possible to use the Tf-idf vectorizer too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9603ec70-34fe-4eda-8f4e-c75e891197b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4161269-702a-4006-9c43-d455bdece2fc",
   "metadata": {},
   "source": [
    "This process has always two steps: \n",
    "\n",
    "1. initialize the vectorizer constructor\n",
    "2. apply `fit_transform` to perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a120ec0-4afc-4456-9e41-801cb7d0ed80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1079x3404 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9065 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    token_pattern=r'\\b[a-zA-Z]{3,}\\b', # we want only words that contain letters and are 3 or more characters long\n",
    ")\n",
    "\n",
    "# Transform our data into the document-term matrix\n",
    "dtm = vectorizer.fit_transform(ads['video_description'])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7574965-face-42cd-a7e7-4b91cdb9ee5f",
   "metadata": {},
   "source": [
    "### Going back to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c44efe-ee5f-40f8-aa8d-988ab464ceec",
   "metadata": {},
   "source": [
    "We can create a function that takes the representation of each document as a row of numbers in the matrix and converts it back to a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523d3de9-d4ce-4674-b832-6b36da164b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2Doc(dtMatrix, features, index):\n",
    "    \"\"\"Turns each row of the document-term matrix into a list of terms\"\"\"\n",
    "    row = dtMatrix.getrow(index).toarray()\n",
    "    non_zero_indices = row.nonzero()[1]\n",
    "    words = [features[idx] for idx in non_zero_indices]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e41e469-d996-4595-9d7d-37e799206555",
   "metadata": {},
   "outputs": [],
   "source": [
    "allAdsAsTerms = [matrix2Doc(dtm, feature_names, i) for i in range(dtm.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba40d9d-9587-479d-a496-c7057c3072ab",
   "metadata": {},
   "source": [
    "Check that we have all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "983e28bb-0490-475a-ac94-81fc5e4e9a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1079"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allAdsAsTerms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d29b95-d2b4-49d0-8a3a-e91c849cddda",
   "metadata": {},
   "source": [
    "Add a column to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "291c44a4-ebf2-4bad-9008-050d4af37769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_timestamp</th>\n",
       "      <th>video_duration</th>\n",
       "      <th>video_locationcreated</th>\n",
       "      <th>suggested_words</th>\n",
       "      <th>video_diggcount</th>\n",
       "      <th>video_sharecount</th>\n",
       "      <th>video_commentcount</th>\n",
       "      <th>video_playcount</th>\n",
       "      <th>video_description</th>\n",
       "      <th>...</th>\n",
       "      <th>video_stickers</th>\n",
       "      <th>author_username</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_followercount</th>\n",
       "      <th>author_followingcount</th>\n",
       "      <th>author_heartcount</th>\n",
       "      <th>author_videocount</th>\n",
       "      <th>author_diggcount</th>\n",
       "      <th>author_verified</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>7342923622752767278</td>\n",
       "      <td>2024-03-05T12:44:54</td>\n",
       "      <td>15.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Skating Board, tubi movie, tubi movies 2023, t...</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1300000.0</td>\n",
       "      <td>They're bringing new vibes to old traditions. ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>tubi</td>\n",
       "      <td>Tubi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>[boarders, bringing, march, new, old, starting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>7340530115241053486</td>\n",
       "      <td>2024-02-28T01:06:58</td>\n",
       "      <td>59.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Karaoke Machine, Karaoke, Playing Karaoke, car...</td>\n",
       "      <td>14200.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>You cant even tell on video how loud this gets...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>kaitttttnicole</td>\n",
       "      <td>Kait</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[definitely, fun, fyp, gets, hype, loud, tell,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7302183353237703967</td>\n",
       "      <td>2023-11-16T17:01:05</td>\n",
       "      <td>35.0</td>\n",
       "      <td>US</td>\n",
       "      <td>heated round brush, wavytalk, wavy talk 5 in 1...</td>\n",
       "      <td>40800.0</td>\n",
       "      <td>3345.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>5400000.0</td>\n",
       "      <td>Replying to @lily  TikTok shop black friday sa...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>julissa_guillen</td>\n",
       "      <td>Julissa Guillen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[amikablowoutbabe, amikablowoutbabedupe, amika...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7313262803266161962</td>\n",
       "      <td>2023-12-16T13:35:03</td>\n",
       "      <td>17.0</td>\n",
       "      <td>US</td>\n",
       "      <td>wavytalk brush, wavy talk, wavy thermal brush,...</td>\n",
       "      <td>157900.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>im not even kidding like this guy is comign w ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>jigglyjulia</td>\n",
       "      <td>julia huynh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[comign, guy, kidding, like, trips]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7336608256384585002</td>\n",
       "      <td>2024-02-17T11:27:29</td>\n",
       "      <td>49.0</td>\n",
       "      <td>US</td>\n",
       "      <td>wavy thermal brush, Thermal Brush, wavytalk br...</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>feeling like this viral @wavytalkofficial is w...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>zoeyburger</td>\n",
       "      <td>zoeyburger</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>[blowout, feeling, hairhack, hype, like, order...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                video_id      video_timestamp  video_duration  \\\n",
       "112  7342923622752767278  2024-03-05T12:44:54            15.0   \n",
       "120  7340530115241053486  2024-02-28T01:06:58            59.0   \n",
       "125  7302183353237703967  2023-11-16T17:01:05            35.0   \n",
       "131  7313262803266161962  2023-12-16T13:35:03            17.0   \n",
       "135  7336608256384585002  2024-02-17T11:27:29            49.0   \n",
       "\n",
       "    video_locationcreated                                    suggested_words  \\\n",
       "112                    US  Skating Board, tubi movie, tubi movies 2023, t...   \n",
       "120                    US  Karaoke Machine, Karaoke, Playing Karaoke, car...   \n",
       "125                    US  heated round brush, wavytalk, wavy talk 5 in 1...   \n",
       "131                    US  wavytalk brush, wavy talk, wavy thermal brush,...   \n",
       "135                    US  wavy thermal brush, Thermal Brush, wavytalk br...   \n",
       "\n",
       "     video_diggcount  video_sharecount  video_commentcount  video_playcount  \\\n",
       "112           1031.0              18.0                12.0        1300000.0   \n",
       "120          14200.0             706.0                65.0         249000.0   \n",
       "125          40800.0            3345.0               355.0        5400000.0   \n",
       "131         157900.0             680.0               315.0        8000000.0   \n",
       "135          10100.0             363.0                66.0        1600000.0   \n",
       "\n",
       "                                     video_description  ...  video_stickers  \\\n",
       "112  They're bringing new vibes to old traditions. ...  ...                   \n",
       "120  You cant even tell on video how loud this gets...  ...                   \n",
       "125  Replying to @lily  TikTok shop black friday sa...  ...                   \n",
       "131  im not even kidding like this guy is comign w ...  ...                   \n",
       "135  feeling like this viral @wavytalkofficial is w...  ...                   \n",
       "\n",
       "     author_username      author_name author_followercount  \\\n",
       "112             tubi             Tubi                        \n",
       "120   kaitttttnicole             Kait                        \n",
       "125  julissa_guillen  Julissa Guillen                        \n",
       "131      jigglyjulia      julia huynh                        \n",
       "135       zoeyburger       zoeyburger                        \n",
       "\n",
       "    author_followingcount author_heartcount author_videocount  \\\n",
       "112                                                             \n",
       "120                                                             \n",
       "125                                                             \n",
       "131                                                             \n",
       "135                                                             \n",
       "\n",
       "    author_diggcount author_verified  \\\n",
       "112                             True   \n",
       "120                            False   \n",
       "125                            False   \n",
       "131                            False   \n",
       "135                            False   \n",
       "\n",
       "                                                 terms  \n",
       "112  [boarders, bringing, march, new, old, starting...  \n",
       "120  [definitely, fun, fyp, gets, hype, loud, tell,...  \n",
       "125  [amikablowoutbabe, amikablowoutbabedupe, amika...  \n",
       "131                [comign, guy, kidding, like, trips]  \n",
       "135  [blowout, feeling, hairhack, hype, like, order...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads['terms'] = allAdsAsTerms\n",
    "ads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba34c1-e132-447c-9304-f084af84e8ff",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "## 3. Fit the LDA model\n",
    "\n",
    "Now that the data is ready and we understand well how it is represented (and how sparse it is), let us fit the LDA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6632eb57-7a22-4e3c-9a6a-8615859147ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=15, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=15, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=15, random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Step 1: Initialize the model\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=15, # we are picking the number of topics arbitrarely at the moment\n",
    "                                random_state=0)\n",
    "\n",
    "# Step 2: Fit the model\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e3ff07",
   "metadata": {},
   "source": [
    "Find top words associated with each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b87bc6dd-7180-426f-b289-ae47c3534a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "skin new moment daily glow video essence girl replying defense invisible watch let primevideo product\n",
      "Topic 1:\n",
      "skin new make chewy pet happy shopping hydration wallet march denim instantly sephora pro smooth\n",
      "Topic 2:\n",
      "sour theaters beans just kids match patch jelly youth new lip text place game best\n",
      "Topic 3:\n",
      "chewy need pets new care start rubs belly minus naturally shop ingredients press sets point\n",
      "Topic 4:\n",
      "new today collection streaming hulu shogun discover right delivered doorstep chewy disney free glow spring\n",
      "Topic 5:\n",
      "new delta terms apply app card like don beach shoe comfort look pay adventure ootd\n",
      "Topic 6:\n",
      "love maxx want fashion easter partner new sale best available ends family march looking spring\n",
      "Topic 7:\n",
      "free unlimited buy line nuuly bbq try like cream pulled pork life customers existing intro\n",
      "Topic 8:\n",
      "limited time new sale good lip balm apply skin success follow steps sensor shop vitamin\n",
      "Topic 9:\n",
      "world discover shop disney day skin nuuly warm easy turn way need walmart let winter\n",
      "Topic 10:\n",
      "save covergirl new time tiktok crush simply members shade easy like march super essence simplyessence\n",
      "Topic 11:\n",
      "shop amazon finds home dress play free summer monopoly time new beaches soaked sun tablet\n",
      "Topic 12:\n",
      "new theaters march fragrance american discover julio starring brow streaming time peacock price comedy swinton\n",
      "Topic 13:\n",
      "dune theaters tickets dunemovie introducing moves cash taking paris earn heard oreal timotheechalamet denisvilleneuve zendaya\n",
      "Topic 14:\n",
      "streaming don miss bacon prime cheez stanicky ricky real cheese john cena medium crackers know\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([features[i]\n",
    "                        for i in topic.argsort()[:-no_top_words-1:-1]])) # syntax for reversing a list [::-1]\n",
    "\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a344c-b155-4fcf-b9e9-5c7c42e7ea3a",
   "metadata": {},
   "source": [
    "### The document-topic matrix and dominant topics\n",
    "\n",
    "In the prior step, by fitting the LDA model, we found the topics that are present in our corpus. Now, we will use these topics to generate the documents. For that, we will use the method `transform`. This method will transform our document-term matrix into a new matrix, the document-topic matrix. This is where the **dimensionality reduction** is happening. We go from the large document-term matrix to a narrow document-topic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f67ac43e-6658-491e-8780-55bcf4cc5f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91515145, 0.00606062, 0.00606061, ..., 0.00606062, 0.00606061,\n",
       "        0.00606061],\n",
       "       [0.00666667, 0.00666667, 0.00666667, ..., 0.00666667, 0.00666667,\n",
       "        0.00666667],\n",
       "       [0.00317461, 0.0031746 , 0.0031746 , ..., 0.0031746 , 0.00317461,\n",
       "        0.0031746 ],\n",
       "       ...,\n",
       "       [0.96888888, 0.00222222, 0.00222222, ..., 0.00222222, 0.00222222,\n",
       "        0.00222222],\n",
       "       [0.00740741, 0.22962934, 0.00740741, ..., 0.00740741, 0.00740741,\n",
       "        0.00740741],\n",
       "       [0.00392157, 0.00392157, 0.00392157, ..., 0.00392157, 0.94509798,\n",
       "        0.00392157]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist = lda.transform(dtm)\n",
    "doc_topic_dist "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5530a8-aee2-45c1-94ac-c8ab708f8f64",
   "metadata": {},
   "source": [
    "Verify the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b9ce858-523f-4005-8efc-63c2a3b1b4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1079, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d732cc5-9f68-426f-88b7-e2fb29532747",
   "metadata": {},
   "source": [
    "**Meaning of the matrix values:** The entries in this matrix represent the proportion of the document's content that is attributed to each topic. This means each row of the output matrix is a distribution over topics for the corresponding document and should sum to one. We can easily test that by getting the sum of a row:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7240d-4f78-4d25-af41-91652de7c104",
   "metadata": {},
   "source": [
    "**Better representing the document-topic matrix**\n",
    "\n",
    "The document-topic matrix above is not very legible, we will create a dataframe that has a better representation. First, I'll modify the function `display_topics` to show a few terms for each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de4a1f92-6803-4591-ae61-dabdf3bdb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayHeader(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    topicNames = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topicNames.append(f\"Topic {topic_idx}: \" + (\", \".join([features[i]\n",
    "                             for i in topic.argsort()[:-no_top_words-1:-1]])))\n",
    "    return topicNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96371208-d821-4f08-8e13-3a148df7dc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0: skin, new, moment, daily, glow</th>\n",
       "      <th>Topic 1: skin, new, make, chewy, pet</th>\n",
       "      <th>Topic 2: sour, theaters, beans, just, kids</th>\n",
       "      <th>Topic 3: chewy, need, pets, new, care</th>\n",
       "      <th>Topic 4: new, today, collection, streaming, hulu</th>\n",
       "      <th>Topic 5: new, delta, terms, apply, app</th>\n",
       "      <th>Topic 6: love, maxx, want, fashion, easter</th>\n",
       "      <th>Topic 7: free, unlimited, buy, line, nuuly</th>\n",
       "      <th>Topic 8: limited, time, new, sale, good</th>\n",
       "      <th>Topic 9: world, discover, shop, disney, day</th>\n",
       "      <th>Topic 10: save, covergirl, new, time, tiktok</th>\n",
       "      <th>Topic 11: shop, amazon, finds, home, dress</th>\n",
       "      <th>Topic 12: new, theaters, march, fragrance, american</th>\n",
       "      <th>Topic 13: dune, theaters, tickets, dunemovie, introducing</th>\n",
       "      <th>Topic 14: streaming, don, miss, bacon, prime</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic 0: skin, new, moment, daily, glow  \\\n",
       "112                                    0.915   \n",
       "120                                    0.007   \n",
       "125                                    0.003   \n",
       "131                                    0.011   \n",
       "135                                    0.005   \n",
       "\n",
       "     Topic 1: skin, new, make, chewy, pet  \\\n",
       "112                                 0.006   \n",
       "120                                 0.007   \n",
       "125                                 0.003   \n",
       "131                                 0.011   \n",
       "135                                 0.005   \n",
       "\n",
       "     Topic 2: sour, theaters, beans, just, kids  \\\n",
       "112                                       0.006   \n",
       "120                                       0.007   \n",
       "125                                       0.003   \n",
       "131                                       0.011   \n",
       "135                                       0.005   \n",
       "\n",
       "     Topic 3: chewy, need, pets, new, care  \\\n",
       "112                                  0.006   \n",
       "120                                  0.007   \n",
       "125                                  0.003   \n",
       "131                                  0.011   \n",
       "135                                  0.005   \n",
       "\n",
       "     Topic 4: new, today, collection, streaming, hulu  \\\n",
       "112                                             0.006   \n",
       "120                                             0.007   \n",
       "125                                             0.003   \n",
       "131                                             0.011   \n",
       "135                                             0.005   \n",
       "\n",
       "     Topic 5: new, delta, terms, apply, app  \\\n",
       "112                                   0.006   \n",
       "120                                   0.007   \n",
       "125                                   0.003   \n",
       "131                                   0.011   \n",
       "135                                   0.005   \n",
       "\n",
       "     Topic 6: love, maxx, want, fashion, easter  \\\n",
       "112                                       0.006   \n",
       "120                                       0.007   \n",
       "125                                       0.003   \n",
       "131                                       0.844   \n",
       "135                                       0.005   \n",
       "\n",
       "     Topic 7: free, unlimited, buy, line, nuuly  \\\n",
       "112                                       0.006   \n",
       "120                                       0.007   \n",
       "125                                       0.003   \n",
       "131                                       0.011   \n",
       "135                                       0.005   \n",
       "\n",
       "     Topic 8: limited, time, new, sale, good  \\\n",
       "112                                    0.006   \n",
       "120                                    0.007   \n",
       "125                                    0.003   \n",
       "131                                    0.011   \n",
       "135                                    0.005   \n",
       "\n",
       "     Topic 9: world, discover, shop, disney, day  \\\n",
       "112                                        0.006   \n",
       "120                                        0.007   \n",
       "125                                        0.003   \n",
       "131                                        0.011   \n",
       "135                                        0.005   \n",
       "\n",
       "     Topic 10: save, covergirl, new, time, tiktok  \\\n",
       "112                                         0.006   \n",
       "120                                         0.907   \n",
       "125                                         0.956   \n",
       "131                                         0.011   \n",
       "135                                         0.005   \n",
       "\n",
       "     Topic 11: shop, amazon, finds, home, dress  \\\n",
       "112                                       0.006   \n",
       "120                                       0.007   \n",
       "125                                       0.003   \n",
       "131                                       0.011   \n",
       "135                                       0.928   \n",
       "\n",
       "     Topic 12: new, theaters, march, fragrance, american  \\\n",
       "112                                              0.006     \n",
       "120                                              0.007     \n",
       "125                                              0.003     \n",
       "131                                              0.011     \n",
       "135                                              0.005     \n",
       "\n",
       "     Topic 13: dune, theaters, tickets, dunemovie, introducing  \\\n",
       "112                                              0.006           \n",
       "120                                              0.007           \n",
       "125                                              0.003           \n",
       "131                                              0.011           \n",
       "135                                              0.005           \n",
       "\n",
       "     Topic 14: streaming, don, miss, bacon, prime  dominant_topic  \n",
       "112                                         0.006               0  \n",
       "120                                         0.007              10  \n",
       "125                                         0.003              10  \n",
       "131                                         0.011               6  \n",
       "135                                         0.005              11  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "topicnames = displayHeader(lda, feature_names, 5)\n",
    "\n",
    "# index names\n",
    "docnames = ads.index.tolist() # We will use the original names of the documents\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(doc_topic_dist, 3), \n",
    "                                 columns=topicnames, \n",
    "                                 index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1) # finds the maximum argument\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2294d8f-d75d-409f-94fc-8600890ef120",
   "metadata": {},
   "source": [
    "### Topic distribution across documents\n",
    "\n",
    "Now that we have the document-topic matrix, we can see which topics show up most frequently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d50b6d83-982f-4214-a09d-719ce7076fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TopicNum</th>\n",
       "      <th>NumDocuments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TopicNum  NumDocuments\n",
       "0          6            96\n",
       "1         11            94\n",
       "2          8            93\n",
       "3          1            93\n",
       "4         12            81\n",
       "5          4            81\n",
       "6          7            71\n",
       "7          2            67\n",
       "8          0            62\n",
       "9          5            61\n",
       "10        14            60\n",
       "11         3            60\n",
       "12        13            54\n",
       "13         9            54\n",
       "14        10            52"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['TopicNum', 'NumDocuments']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3071b0-4bf2-4dc8-b805-ad060d93546b",
   "metadata": {},
   "source": [
    "### Add two more columns\n",
    "\n",
    "1. a column with the top 10 words of the corresponding topic. (see Topic Num for the topic number)\n",
    "2. a column that lists the document names associated with the topic (document names are things like food_1, food_2, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d4dcd",
   "metadata": {},
   "source": [
    "#### Column 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed6d9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top10_word_in_topics(row, model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top 10 words in a topic\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        if row[\"TopicNum\"] == topic_idx:\n",
    "            return \" \".join([features[i] for i in topic.argsort()[:-no_top_words-1:-1]]) # syntax for reversing a list [::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8067b54-8ddd-4715-a8a2-75d07369491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution['top10'] = df_topic_distribution.apply(display_top10_word_in_topics,args= (lda, feature_names,10), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e03edc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TopicNum</th>\n",
       "      <th>NumDocuments</th>\n",
       "      <th>top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>love maxx want fashion easter partner new sale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>94</td>\n",
       "      <td>shop amazon finds home dress play free summer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>limited time new sale good lip balm apply skin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>skin new make chewy pet happy shopping hydrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>new theaters march fragrance american discover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>new today collection streaming hulu shogun dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>free unlimited buy line nuuly bbq try like cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>sour theaters beans just kids match patch jell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>skin new moment daily glow video essence girl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>new delta terms apply app card like don beach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>streaming don miss bacon prime cheez stanicky ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>chewy need pets new care start rubs belly minu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "      <td>dune theaters tickets dunemovie introducing mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>world discover shop disney day skin nuuly warm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>save covergirl new time tiktok crush simply me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TopicNum  NumDocuments                                              top10\n",
       "0          6            96  love maxx want fashion easter partner new sale...\n",
       "1         11            94  shop amazon finds home dress play free summer ...\n",
       "2          8            93  limited time new sale good lip balm apply skin...\n",
       "3          1            93  skin new make chewy pet happy shopping hydrati...\n",
       "4         12            81  new theaters march fragrance american discover...\n",
       "5          4            81  new today collection streaming hulu shogun dis...\n",
       "6          7            71  free unlimited buy line nuuly bbq try like cre...\n",
       "7          2            67  sour theaters beans just kids match patch jell...\n",
       "8          0            62  skin new moment daily glow video essence girl ...\n",
       "9          5            61  new delta terms apply app card like don beach ...\n",
       "10        14            60  streaming don miss bacon prime cheez stanicky ...\n",
       "11         3            60  chewy need pets new care start rubs belly minu...\n",
       "12        13            54  dune theaters tickets dunemovie introducing mo...\n",
       "13         9            54  world discover shop disney day skin nuuly warm...\n",
       "14        10            52  save covergirl new time tiktok crush simply me..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ac2dc",
   "metadata": {},
   "source": [
    "#### Column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9c43c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_doc(row):\n",
    "    \"\"\"Helper function to display the document names associated with the topic\"\"\"\n",
    "    docs = df_document_topic[df_document_topic['dominant_topic'] == row['TopicNum']]\n",
    "    return docs.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8853aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution['docs'] = df_topic_distribution.apply(display_doc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60ce024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TopicNum</th>\n",
       "      <th>NumDocuments</th>\n",
       "      <th>top10</th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>love maxx want fashion easter partner new sale...</td>\n",
       "      <td>[131, 164, 229, 266, 432, 458, 554, 580, 623, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>94</td>\n",
       "      <td>shop amazon finds home dress play free summer ...</td>\n",
       "      <td>[135, 307, 311, 321, 699, 742, 765, 1153, 1455...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>limited time new sale good lip balm apply skin...</td>\n",
       "      <td>[139, 254, 385, 406, 527, 819, 849, 855, 920, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>skin new make chewy pet happy shopping hydrati...</td>\n",
       "      <td>[208, 240, 260, 467, 591, 682, 754, 860, 936, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>new theaters march fragrance american discover...</td>\n",
       "      <td>[378, 442, 453, 564, 575, 642, 869, 873, 1340,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>new today collection streaming hulu shogun dis...</td>\n",
       "      <td>[655, 808, 984, 1006, 1132, 1169, 1359, 1478, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>free unlimited buy line nuuly bbq try like cre...</td>\n",
       "      <td>[394, 471, 487, 595, 613, 725, 1064, 1198, 125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>sour theaters beans just kids match patch jell...</td>\n",
       "      <td>[143, 170, 201, 222, 273, 301, 315, 366, 462, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>skin new moment daily glow video essence girl ...</td>\n",
       "      <td>[112, 289, 360, 399, 436, 558, 633, 651, 760, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>new delta terms apply app card like don beach ...</td>\n",
       "      <td>[295, 662, 748, 777, 783, 989, 1068, 1164, 171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>streaming don miss bacon prime cheez stanicky ...</td>\n",
       "      <td>[147, 326, 346, 419, 423, 491, 542, 546, 617, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>chewy need pets new care start rubs belly minu...</td>\n",
       "      <td>[333, 339, 353, 427, 475, 549, 600, 732, 927, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>54</td>\n",
       "      <td>dune theaters tickets dunemovie introducing mo...</td>\n",
       "      <td>[215, 480, 605, 622, 674, 865, 961, 998, 1056,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>world discover shop disney day skin nuuly warm...</td>\n",
       "      <td>[247, 628, 669, 675, 903, 923, 971, 1042, 1364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>save covergirl new time tiktok crush simply me...</td>\n",
       "      <td>[120, 125, 412, 533, 609, 638, 913, 1172, 1396...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TopicNum  NumDocuments                                              top10  \\\n",
       "0          6            96  love maxx want fashion easter partner new sale...   \n",
       "1         11            94  shop amazon finds home dress play free summer ...   \n",
       "2          8            93  limited time new sale good lip balm apply skin...   \n",
       "3          1            93  skin new make chewy pet happy shopping hydrati...   \n",
       "4         12            81  new theaters march fragrance american discover...   \n",
       "5          4            81  new today collection streaming hulu shogun dis...   \n",
       "6          7            71  free unlimited buy line nuuly bbq try like cre...   \n",
       "7          2            67  sour theaters beans just kids match patch jell...   \n",
       "8          0            62  skin new moment daily glow video essence girl ...   \n",
       "9          5            61  new delta terms apply app card like don beach ...   \n",
       "10        14            60  streaming don miss bacon prime cheez stanicky ...   \n",
       "11         3            60  chewy need pets new care start rubs belly minu...   \n",
       "12        13            54  dune theaters tickets dunemovie introducing mo...   \n",
       "13         9            54  world discover shop disney day skin nuuly warm...   \n",
       "14        10            52  save covergirl new time tiktok crush simply me...   \n",
       "\n",
       "                                                 docs  \n",
       "0   [131, 164, 229, 266, 432, 458, 554, 580, 623, ...  \n",
       "1   [135, 307, 311, 321, 699, 742, 765, 1153, 1455...  \n",
       "2   [139, 254, 385, 406, 527, 819, 849, 855, 920, ...  \n",
       "3   [208, 240, 260, 467, 591, 682, 754, 860, 936, ...  \n",
       "4   [378, 442, 453, 564, 575, 642, 869, 873, 1340,...  \n",
       "5   [655, 808, 984, 1006, 1132, 1169, 1359, 1478, ...  \n",
       "6   [394, 471, 487, 595, 613, 725, 1064, 1198, 125...  \n",
       "7   [143, 170, 201, 222, 273, 301, 315, 366, 462, ...  \n",
       "8   [112, 289, 360, 399, 436, 558, 633, 651, 760, ...  \n",
       "9   [295, 662, 748, 777, 783, 989, 1068, 1164, 171...  \n",
       "10  [147, 326, 346, 419, 423, 491, 542, 546, 617, ...  \n",
       "11  [333, 339, 353, 427, 475, 549, 600, 732, 927, ...  \n",
       "12  [215, 480, 605, 622, 674, 865, 961, 998, 1056,...  \n",
       "13  [247, 628, 669, 675, 903, 923, 971, 1042, 1364...  \n",
       "14  [120, 125, 412, 533, 609, 638, 913, 1172, 1396...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a872c0-923b-4c7f-9afb-cd05455cc901",
   "metadata": {},
   "source": [
    "<a id=\"sec4\"></a>\n",
    "## 4. Grid Search: Find number of topics\n",
    "\n",
    "In the example so far, we arbitrarely chose the number of topics to be 15. However, that is not the right way to go about it. We whould use methods for selecting the optimal number of topics. This can be done through a mechanism known as GridSearch with cross-validation that builds multiple models and then compares them to see which one performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38e66c50-a2da-4a3d-a6ca-90ee1ab576b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={&#x27;n_components&#x27;: [5, 10, 15, 20, 25, 30, 35]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={&#x27;n_components&#x27;: [5, 10, 15, 20, 25, 30, 35]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'n_components': [5, 10, 15, 20, 25, 30, 35]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We are going to test multiple values for the number of topics\n",
    "search_params = {'n_components': [5, 10, 15, 20, 25, 30, 35]}\n",
    "\n",
    "# Initialize the LDA model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Initialize a Grid Search with cross-validation instance\n",
    "grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "grid.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf126a6-327f-4a89-9b37-c2cf483c987c",
   "metadata": {},
   "source": [
    "Let us look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0a55148-df6e-42ba-b11d-2cd2179f2226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.31691394, 0.29247179, 0.27941689, 0.27942915, 0.28690066,\n",
       "        0.29683456, 0.30405126]),\n",
       " 'std_fit_time': array([0.0165243 , 0.02506067, 0.00244721, 0.00238839, 0.00381297,\n",
       "        0.00141829, 0.00326779]),\n",
       " 'mean_score_time': array([0.01058421, 0.0105722 , 0.01031303, 0.0103229 , 0.01064243,\n",
       "        0.00983582, 0.00972252]),\n",
       " 'std_score_time': array([0.00056811, 0.00092465, 0.00050051, 0.00034589, 0.0001279 ,\n",
       "        0.00033557, 0.00017553]),\n",
       " 'param_n_components': masked_array(data=[5, 10, 15, 20, 25, 30, 35],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_components': 5},\n",
       "  {'n_components': 10},\n",
       "  {'n_components': 15},\n",
       "  {'n_components': 20},\n",
       "  {'n_components': 25},\n",
       "  {'n_components': 30},\n",
       "  {'n_components': 35}],\n",
       " 'split0_test_score': array([-22661.59831765, -27675.88185918, -31937.94972332, -35674.48672861,\n",
       "        -39389.55672467, -43773.18169067, -47375.33787052]),\n",
       " 'split1_test_score': array([-24577.71458311, -29999.33870097, -34573.87662485, -38902.28470499,\n",
       "        -42951.72509148, -47328.84667031, -51035.6369114 ]),\n",
       " 'split2_test_score': array([-20956.96406487, -25252.62919588, -28727.89198829, -31789.43149854,\n",
       "        -34729.50571327, -37257.0343032 , -39991.95272322]),\n",
       " 'split3_test_score': array([-24241.7158103 , -29117.79820681, -33163.82414748, -36973.4344193 ,\n",
       "        -40520.7750114 , -44072.83175365, -47401.46696778]),\n",
       " 'split4_test_score': array([-24041.62953676, -29167.05136876, -33535.35157356, -37571.34458259,\n",
       "        -41304.29979192, -45098.33756524, -48839.38029054]),\n",
       " 'mean_test_score': array([-23295.92446254, -28242.53986632, -32387.7788115 , -36182.1963868 ,\n",
       "        -39779.17246655, -43506.04639662, -46928.75495269]),\n",
       " 'std_test_score': array([1339.15560294, 1671.39510233, 2014.71144458, 2429.35478073,\n",
       "        2778.20131008, 3364.28156218, 3716.42534506]),\n",
       " 'rank_test_score': array([1, 2, 3, 4, 5, 6, 7], dtype=int32)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412e2f6-56d8-4b82-a667-5b934a0ea374",
   "metadata": {},
   "source": [
    "Since this representation is a bit overwhelming, let's access a few features of the grid instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1a27fe7-3704-43a4-beea-69d5898d00ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'n_components': 5}\n",
      "Best Log Likelihood Score:  -23295.924462537158\n",
      "Model Perplexity:  2965.9465658789786\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ede5a-61a2-40fc-95c0-1272f3e39c76",
   "metadata": {},
   "source": [
    "The results are showing that the best LDA model should have 5 topics, the smallest number we tried. This raises the question of whether we should try other small numbers, which I'm doing below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e6ff1e3-c05c-48eb-85c8-2c55979d00fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'n_components': 1}\n",
      "Best Log Likelihood Score:  -17346.95820992014\n",
      "Model Perplexity:  2702.786354244111\n"
     ]
    }
   ],
   "source": [
    "search_params = {'n_components': [1,2,3,4,5,6]}\n",
    "\n",
    "lda = LatentDirichletAllocation()\n",
    "grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "grid.fit(dtm)\n",
    "\n",
    "# Best Model\n",
    "best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43140116-4981-40ae-a3f5-b3a3968fc7a1",
   "metadata": {},
   "source": [
    "This result shows that actually the best number of topics for this corpus is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad0057-13ff-4bd1-8697-f4d94c24be0e",
   "metadata": {},
   "source": [
    "**Meaning of Log Likelihood**. \n",
    "\n",
    "Log Likelihood is the logarithm of the probability of observing the given data under the model with specific parameters. Essentially, it measures how well the model explains the observed data. (It is a conditional probability.)\n",
    "\n",
    "**Meaning of perplexity**\n",
    "\n",
    "Perplexity is a common metric used to evaluate the quality of probabilistic models. It reflects how well the model describes or predicts the documents in the dataset.\n",
    "\n",
    "A lower perplexity score suggests that the model is more certain about its predictions (i.e., the probability distributions it assigns to unseen documents are more accurate). This means that the topic distributions learned by the model are a good fit for the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d0ca2-e901-498b-9555-36906db69ffe",
   "metadata": {},
   "source": [
    "**Words for best modesl with one topic**\n",
    "\n",
    "Let's see what are the top words for the best model with one topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3b987c2-8a89-4576-b876-ef434a14c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "new skin shop free time march love make today don chewy theaters amazon like sale collection limited streaming discover just try glow best finds dress fashion spring miss want good lip home cream body shopping hulu start need care maxx\n"
     ]
    }
   ],
   "source": [
    "display_topics(best_lda_model, feature_names, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20193f66-1255-49c4-acda-146fc9407c4e",
   "metadata": {},
   "source": [
    "As we can see it is a mix of food and realestae and New York. If we had documents with more distinct nature and more of them we might have seen something else. \n",
    "\n",
    "However, the point of this tutorial was to show the mechanics of building LDA models. \n",
    "\n",
    "Now it's time to take what you saw here and apply it to your projects.\n",
    "\n",
    "Have fun exploring!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
